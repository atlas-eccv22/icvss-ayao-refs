## Citations List

#### 2023
- VideoLLM: Modeling Video Sequence with Large Language Models, 
    [[pdf]](https://arxiv.org/pdf/2305.13292.pdf)
    - Guo Chen, Yin-Dong Zheng, Jiahao Wang, Jilan Xu, Yifei Huang, Junting Pan, Yi Wang et al., *arXiv 2023*
- StepFormer: Self-supervised Step Discovery and Localization in Instructional Videos
    [[pdf]](https://openaccess.thecvf.com/content/CVPR2023/papers/Dvornik_StepFormer_Self-Supervised_Step_Discovery_and_Localization_in_Instructional_Videos_CVPR_2023_paper.pdf)
    - Nikita Dvornik, Isma Hadji, Ran Zhang, Konstantinos G. Derpanis, Richard P. Wildes, and Allan D. Jepson, *CVPR 2023*
- HierVL: Learning Hierarchical Video-Language Embeddings
    [[pdf]](https://openaccess.thecvf.com/content/CVPR2023/papers/Ashutosh_HierVL_Learning_Hierarchical_Video-Language_Embeddings_CVPR_2023_paper.pdf)
    - Kumar Ashutosh, Rohit Girdhar, Lorenzo Torresani, and Kristen Grauman, *CVPR 2023*
- C2F-TCN: A Framework for Semi- and Fully-Supervised Temporal Action Segmentation
    [[pdf]](https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10147035)
    - Dipika Singhania, Singhania, Dipika, Rahul Rahaman, and Angela Yao, *TPAMI 2023*

#### 2022
- Assembly101: A Large-Scale Multi-View Video Dataset for Understanding Procedural Activities
  [[pdf]](https://openaccess.thecvf.com/content/CVPR2022/papers/Sener_Assembly101_A_Large-Scale_Multi-View_Video_Dataset_for_Understanding_Procedural_Activities_CVPR_2022_paper.pdf)
  [[page]](https://assembly-101.github.io/)
    - Fadime Sener, Dibyadip Chatterjee, Daniel Shelepov, Kun He, Dipika Singhania, Robert Wang, and Angela Yao, *CVPR 2022*.
- Ego4D: Around the World in 3,000 Hours of Egocentric Video,
  [[pdf]](https://openaccess.thecvf.com/content/CVPR2022/papers/Grauman_Ego4D_Around_the_World_in_3000_Hours_of_Egocentric_Video_CVPR_2022_paper.pdf)
  [[page]](https://ego4d-data.org/)
    - Kristen Grauman, Andrew Westbury, Eugene Byrne, Zachary Chavis, Antonino Furnari, Rohit Girdhar, Jackson Hamburger et al. , *CVPR 2022*.
